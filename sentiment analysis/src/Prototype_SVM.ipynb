{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing packages \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/paul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/paul/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# loading the stopwords library\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \"\"\"Le Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, trainfile):\n",
    "        \"\"\"Trains the classifier model on the training set stored in file trainfile\"\"\"\n",
    "        # Loading the training data\n",
    "        train_data = pd.read_csv(trainfile, sep = \"\\t\",\n",
    "                                 names = [\"sentiment\", \"subject\", \"word\", \"timestamp\", \"original_text\"])\n",
    "        \n",
    "        # first lower the text \n",
    "        train_data['text'] = train_data['original_text'].apply(str.lower)\n",
    "        # parse the words\n",
    "        # we want to emphasize that there are special care to take about the word not and its contractions: \n",
    "        # it might be useful to keep them\n",
    "        train_data['text'] = train_data[\"text\"].apply(lambda sentence: sentence.replace(\"can\\'t\", \"can not\"))\n",
    "        train_data['text'] = train_data[\"text\"].apply(lambda sentence: sentence.replace(\"n\\'t\", \" not\"))\n",
    "        train_data['words'] = train_data[\"text\"].apply(lambda sentence:  \"\".join((char if char.isalpha() else \" \") for char in sentence).lower().split() )\n",
    "        \n",
    "        # getting rid off stopwords\n",
    "        self.stopwords = stopwords.words(\"english\")\n",
    "        self.stopwords.remove(\"not\")\n",
    "        \n",
    "        train_data['words'] = train_data[\"words\"].apply(lambda words : [word for word in words if word not in self.stopwords])\n",
    "        \n",
    "        # stemming the words with a Porter Stemmer\n",
    "        stemmer = nltk.porter.PorterStemmer()\n",
    "        train_data['stems'] = train_data[\"words\"].apply(lambda words : [stemmer.stem(word) for word in words])\n",
    "        \n",
    "\n",
    "        self.sentiments = pd.get_dummies(train_data['sentiment'])\n",
    "        \n",
    "\n",
    "        print(\"Starting Word Embedding\")\n",
    "        train_data['vectors'] = train_data['stems'].apply(get_word_embeddings)\n",
    "        \n",
    "        \n",
    "        def padding(vectors, length = 36):\n",
    "            vectors = np.array(vectors)\n",
    "            size = vectors.shape[1]\n",
    "        #train_data['mean_vector'] = train_data['vectors'].apply(lambda x: np.mean(x, axis = 0))\n",
    "        # Storing the training data into an attribute of the Classifier\n",
    "        self.data_train = train_data\n",
    "        \n",
    "        # keeping the categories that we will be trying to predict\n",
    "        self.label_categories = pd.get_dummies(train_data['subject'])\n",
    "        self.categories = self.label_categories.columns\n",
    "        self.label_sentiment = train_data['sentiment']\n",
    "        \"\"\"\n",
    "        # perform wordcount\n",
    "        word_count = {}\n",
    "        for row in train_data['stems']:\n",
    "            for word in row:\n",
    "                if word in word_count.keys():\n",
    "                    word_count[word]+=1\n",
    "                else:\n",
    "                    word_count[word]=1\n",
    "                \n",
    "        self.vocabulary = np.unique(word_count.keys())\n",
    "        self.word_count = word_count\n",
    "        \"\"\"\n",
    "        \n",
    "    def predict(self, datafile):\n",
    "        \"\"\"Predicts class labels for the input instances in file 'datafile'\n",
    "        Returns the list of predicted labels\n",
    "        \"\"\"\n",
    "        raise(NotImplemented('Implement it !'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/traindata.csv\", sep = \"\\t\",\n",
    "                                 names = [\"sentiment\", \"subject\", \"word\", \"timestamp\", \"original_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subject</th>\n",
       "      <th>word</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>seating</td>\n",
       "      <td>18:25</td>\n",
       "      <td>short and sweet – seating is great:it's romant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>trattoria</td>\n",
       "      <td>25:34</td>\n",
       "      <td>This quaint and romantic trattoria is at the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>food</td>\n",
       "      <td>98:102</td>\n",
       "      <td>The have over 100 different beers to offer thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>STAFF</td>\n",
       "      <td>5:10</td>\n",
       "      <td>THIS STAFF SHOULD BE FIRED.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>menu</td>\n",
       "      <td>4:8</td>\n",
       "      <td>The menu looked great, and the waiter was very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment             subject       word timestamp  \\\n",
       "0  positive    AMBIENCE#GENERAL    seating     18:25   \n",
       "1  positive    AMBIENCE#GENERAL  trattoria     25:34   \n",
       "2  positive        FOOD#QUALITY       food    98:102   \n",
       "3  negative     SERVICE#GENERAL      STAFF      5:10   \n",
       "4  positive  FOOD#STYLE_OPTIONS       menu       4:8   \n",
       "\n",
       "                                       original_text  \n",
       "0  short and sweet – seating is great:it's romant...  \n",
       "1  This quaint and romantic trattoria is at the t...  \n",
       "2  The have over 100 different beers to offer thi...  \n",
       "3                        THIS STAFF SHOULD BE FIRED.  \n",
       "4  The menu looked great, and the waiter was very...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "train_data['words'] = train_data[\"original_text\"].apply(lambda sentence:  \"\".join((char if char.isalpha() else \" \") for char in sentence).lower().split() )\n",
    "train_data['words'] = train_data['words'].apply(lambda words : [word for word in words if word not in stopwords ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pos_tagging'] = train_data['words'].apply(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['pos_tagging_string'] = train_data.pos_tagging.apply(lambda pos_labels: [tuple2string(x) for x in pos_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for index, words in enumerate(train_data.pos_tagging_string):\n",
    "    for pos in words :\n",
    "        if pos in vocabulary.keys():\n",
    "            vocabulary[pos]+=[index]\n",
    "        else :\n",
    "            vocabulary[pos]=[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for tag in vocabulary.keys():\n",
    "    train_data[tag]=0\n",
    "    for index in vocabulary[tag]:\n",
    "        train_data[tag][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple2string(tup):\n",
    "    return str(tup[0] + '_' + tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [short_JJ, sweet_NN, seating_VBG, great_JJ, ro...\n",
       "1       [quaint_NN, romantic_JJ, trattoria_NN, top_JJ,...\n",
       "2       [different_JJ, beers_NNS, offer_VBP, thier_JJR...\n",
       "3                                   [staff_NN, fired_VBD]\n",
       "4       [menu_NN, looked_VBD, great_JJ, waiter_NN, nic...\n",
       "5        [tuna_NN, wasabe_NN, potatoes_NNS, excellent_JJ]\n",
       "6       [whole_JJ, set_VBN, truly_RB, unprofessional_J...\n",
       "7       [sometimes_RB, get_VB, bad_JJ, food_NN, bad_JJ...\n",
       "8       [place_NN, best_JJS, chinese_JJ, style_NN, bbq...\n",
       "9       [great_JJ, place_NN, relax_NN, enjoy_NN, dinne...\n",
       "10      [bread_NN, received_VBD, horrible_JJ, rock_NN,...\n",
       "11      [thought_JJ, place_NN, using_VBG, much_JJ, msg...\n",
       "12      [always_RB, good_JJ, drinks_NNS, service_NN, p...\n",
       "13      [particular_JJ, sushi_NN, please_NN, every_DT,...\n",
       "14      [prix_NN, fixe_NN, menu_NN, worth_NN, every_DT...\n",
       "15      [scallops_NNS, appetizer_VBP, delicious_JJ, sa...\n",
       "16      [ambience_NN, cute_NN, quaint_NN, good_JJ, bus...\n",
       "17      [best_JJS, part_NN, ls_NN, late_JJ, night_NN, ...\n",
       "18      [dessert_NN, pear_JJ, torte_RB, good_JJ, staff...\n",
       "19      [pesto_NN, pizza_NN, excellent_JJ, thin_JJ, cr...\n",
       "20      [fish_JJ, husband_NN, filet_NN, exceeded_VBD, ...\n",
       "21      [quesadilla_RB, tasted_VBN, like_IN, made_VBN,...\n",
       "22                     [place_NN, incredibly_RB, tiny_JJ]\n",
       "23      [found_VBN, food_NN, outstanding_JJ, particula...\n",
       "24                  [service_NN, prompt_NN, courteous_JJ]\n",
       "25      [delicious_JJ, bagels_NNS, especially_RB, righ...\n",
       "26      [never_RB, left_VBN, restaurant_NN, feeling_NN...\n",
       "27      [husband_NN, said_VBD, could_MD, eaten_VB, sev...\n",
       "28      [also_RB, recommend_VB, rice_NN, dishes_NNS, d...\n",
       "29      [highly_RB, recommend_JJ, cafe_NN, st_NN, bart...\n",
       "                              ...                        \n",
       "1473    [like_IN, somosas_NNS, chai_VBP, chole_JJ, dho...\n",
       "1474                       [really_RB, good_JJ, pizza_NN]\n",
       "1475                 [service_NN, quick_NNS, friendly_RB]\n",
       "1476    [great_JJ, food_NN, great_JJ, decor_NN, great_...\n",
       "1477                               [lloovve_JJ, place_NN]\n",
       "1478    [service_NN, also_RB, horrible_JJ, ambience_NN...\n",
       "1479    [mussles_NNS, fishiest_JJS, things_NNS, ever_R...\n",
       "1480    [sum_JJ, service_NN, varies_NNS, good_JJ, medi...\n",
       "1481    [boring_VBG, inside_IN, sushi_JJ, pretty_JJ, a...\n",
       "1482    [great_JJ, toppings_NNS, definitely_RB, place_...\n",
       "1483    [like_IN, music_NN, blasted_VBN, system_NN, is...\n",
       "1484                      [good_JJ, wine_NN, choices_NNS]\n",
       "1485    [everything_NN, wonderful_JJ, food_NN, drinks_...\n",
       "1486    [place_NN, got_VBD, best_JJS, japanese_JJ, res...\n",
       "1487    [wait_NN, summer_NN, serve_VB, outside_JJ, gig...\n",
       "1488    [terrible_JJ, terrible_JJ, management_NN, dese...\n",
       "1489    [best_JJS, warm_NN, vibe_NN, owner_NN, super_V...\n",
       "1490    [love_NN, atmosphere_RB, felt_VBD, like_IN, pa...\n",
       "1491    [worried_VBN, would_MD, trouble_NN, getting_VB...\n",
       "1492                                   [food_NN, good_NN]\n",
       "1493    [bread_NN, received_VBD, horrible_JJ, rock_NN,...\n",
       "1494    [went_VBD, lunch_NN, good_NN, expected_VBN, re...\n",
       "1495       [bison_NN, quite_RB, excellent_JJ, however_RB]\n",
       "1496    [sometimes_RB, get_VB, bad_JJ, food_NN, bad_JJ...\n",
       "1497    [ordered_VBN, beef_NN, noodle_JJ, soup_NN, dis...\n",
       "1498    [one_CD, us_PRP, actually_RB, liked_VBD, expre...\n",
       "1499    [hostess_NN, waitress_NN, incredibly_RB, rude_...\n",
       "1500    [little_JJ, place_NN, cute_NN, interior_JJ, de...\n",
       "1501    [nice_JJ, family_NN, owned_VBD, traditional_JJ...\n",
       "1502    [first_JJ, time_NN, went_VBD, completely_RB, t...\n",
       "Name: pos_tagging_string, Length: 1503, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.pos_tagging_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
